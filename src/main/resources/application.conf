#log4j.rootLogger=INFO, console
#log4j.appender.console=org.apache.log4j.ConsoleAppender
#log4j.appender.console.layout=org.apache.log4j.PatternLayout
#log4j.appender.console.layout.ConversionPattern=%d{HH:mm:ss,SSS} %-5p %-60c %x - %m%n

conproducer10 {
  bootstrap.servers = "flink01:9092"
  key.serializer = "org.apache.kafka.common.serialization.IntegerSerializer"
  value.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  # partitioner.class = "InpeParse.MyPartitioner"
  acks = "all"
  compression.type = "none" #"none" # none, gzip, snappy, or lz4
  batch.size = "16384" #"1048576"
  linger.ms = "5" # group records if arriving within 5ms
  request.timeout.ms = "100000"
}


outproducer10 {
  bootstrap.servers = "flink01:9092"
  acks = "all"
  compression.type = "lz4" # none, gzip, snappy, or lz4
  batch.size = "16384" #"1048576"
  linger.ms = "5" # group records if arriving within 5ms
  request.timeout.ms = "100000"
}

outconsumer10 {
  bootstrap.servers = "flink01:9092"
  # auto.offset.reset = "earliest"
  request.timeout.ms = "100000"
}

conconsumer10 {
  bootstrap.servers = "flink01:9092"
  request.timeout.ms = "100000"
  key.deserializer = "org.apache.kafka.common.serialization.IntegerDeserializer"
  value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
  # auto.offset.reset = "earliest"
  group.id = "flink-control"
}

rapi {
  rapipar = "4"
  header = "file:///tmp/ref/bamheader"
  sref = "/tmp/ref/chr1.fasta"
}